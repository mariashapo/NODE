{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "import jax\n",
    "import optax\n",
    "\n",
    "from jax import jacfwd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "collocation2_path = os.path.abspath(os.path.join('..', 'collocation2'))\n",
    "\n",
    "# Add the directory to sys.path\n",
    "if collocation2_path not in sys.path:\n",
    "    sys.path.append(collocation2_path)\n",
    "\n",
    "from interpolation import BarycentricInterpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network with Flax\n",
    "class SimpleNN(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(128)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(64)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(2)(x)  # Assuming a 2D output for u and v\n",
    "        return x\n",
    "\n",
    "# Initialize the neural network\n",
    "def create_model():\n",
    "    model = SimpleNN()\n",
    "    return model\n",
    "\n",
    "# Initialize parameters\n",
    "def init_model_params(model, rng, input_shape):\n",
    "    params = model.init(rng, jnp.ones(input_shape))\n",
    "    return params\n",
    "\n",
    "# Define the forward function\n",
    "def model_forward(params, x):\n",
    "    return SimpleNN().apply(params, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training state\n",
    "def create_train_state(rng, learning_rate, model, input_shape):\n",
    "    params = init_model_params(model, rng, input_shape)\n",
    "    tx = optax.adam(learning_rate)\n",
    "    return train_state.TrainState.create(apply_fn=model.apply, params=params, tx=tx)\n",
    "\n",
    "# Define a loss function\n",
    "def compute_loss(params, batch):\n",
    "    preds = model_forward(params, batch['inputs'])\n",
    "    loss = jnp.mean((preds - batch['targets']) ** 2)\n",
    "    return loss\n",
    "\n",
    "# Training step\n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    loss_fn = lambda params: compute_loss(params, batch)\n",
    "    grads = jax.grad(loss_fn)(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state\n",
    "\n",
    "# Dummy data for demonstration\n",
    "rng = jax.random.PRNGKey(0)\n",
    "input_shape = (10, 2)  # Example input shape\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "\n",
    "# Initialize model and state\n",
    "model = create_model()\n",
    "state = create_train_state(rng, learning_rate, model, input_shape)\n",
    "\n",
    "# Example training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Dummy batch for demonstration\n",
    "    batch = {'inputs': jax.random.normal(rng, input_shape), 'targets': jax.random.normal(rng, input_shape)}\n",
    "    state = train_step(state, batch)\n",
    "\n",
    "# Trained parameters\n",
    "trained_params = state.params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagrange_basis(t, k, t_grid):\n",
    "    terms = [(t - t_grid[m]) / (t_grid[k] - t_grid[m]) for m in range(len(t_grid)) if m != k]\n",
    "    return jnp.prod(jnp.array(terms))\n",
    "\n",
    "\n",
    "def interpolate(u, t, t_grid):\n",
    "    \"\"\"\n",
    "    u: The array of function values at the grid points\n",
    "    t: The point at which to interpolate\n",
    "    t_grid: The array of interpolation nodes\n",
    "    \"\"\"\n",
    "    if u.ndim == 1:\n",
    "        return jnp.sum(jnp.array([u_k * lagrange_basis(t, k, t_grid) for k, u_k in enumerate(u)]))\n",
    "    return jnp.array([jnp.sum(jnp.array([u_k[i] * lagrange_basis(t, k, t_grid) for k, u_k in enumerate(u)])) for i in range(u.shape[1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained neural network as the function f\n",
    "def neural_net_f(t, uv, params):\n",
    "    return model_forward(params, uv)\n",
    "\n",
    "# Modify the solver to pass the neural network parameters\n",
    "def newton_method_nn(u_init, t_grid, f, params, u0=1, tol=1e-6, max_iter=20):\n",
    "    \"\"\"\n",
    "    Solves a system of nonlinear equations using Newton's method with a neural network.\n",
    "    \n",
    "    Parameters:\n",
    "    u_init : ndarray\n",
    "        Initial guess for the solution.\n",
    "    t_grid : ndarray\n",
    "        Grid points where the solution is evaluated.\n",
    "    f : function\n",
    "        The function defining the system of differential equations.\n",
    "    params : dict\n",
    "        Trained parameters of the neural network.\n",
    "    u0 : float or ndarray, optional\n",
    "        Initial condition for the system (default is 1).\n",
    "    tol : float, optional\n",
    "        Tolerance for the norm of the update (default is 1e-6).\n",
    "    max_iter : int, optional\n",
    "        Maximum number of iterations (default is 100).\n",
    "    \n",
    "    Returns:\n",
    "    ndarray\n",
    "        The solution vector.\n",
    "    \n",
    "    Raises:\n",
    "    ValueError\n",
    "        If Newton's method did not converge.\n",
    "    \"\"\"\n",
    "    u = u_init\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        F_u = system(u, t_grid, f, u0, params)\n",
    "        \n",
    "        # Compute the Jacobian matrix of the system at u\n",
    "        J_u = jacfwd(system, argnums=0)(u, t_grid, f, u0, params)\n",
    "        \n",
    "        # Flatten the Jacobian and F_u for solving\n",
    "        F_u_flat = F_u.reshape(-1)\n",
    "        J_u_flat = J_u.reshape(F_u_flat.shape[0], -1)\n",
    "        \n",
    "        # Solve for the update Δu in the linear system J(u) Δu = -F(u)\n",
    "        delta_u_flat = jnp.linalg.solve(J_u_flat, -F_u_flat)\n",
    "        \n",
    "        # Reshape the update and apply\n",
    "        delta_u = delta_u_flat.reshape(u.shape)\n",
    "        u = u + delta_u\n",
    "        \n",
    "        norm_delta_u = jnp.linalg.norm(delta_u)\n",
    "        if norm_delta_u < tol:\n",
    "            print(f\"Converged at iteration {i+1}\")\n",
    "            return u\n",
    "    \n",
    "    raise ValueError(\"Newton's method did not converge\")\n",
    "\n",
    "# Update system function to pass the neural network parameters\n",
    "def system(u, t_grid, f, u0, params):\n",
    "    u0 = jnp.array([1.0, 0.0])  # Initial condition u(0) = 1, v(0) = 0\n",
    "    eqs = [u[0] - u0]\n",
    "    \n",
    "    for k in range(1, len(t_grid)):\n",
    "        eq = u[k] - u[k-1] - integral(f, t_grid[k-1], t_grid[k], u, t_grid, params)\n",
    "        eqs.append(eq)\n",
    "    \n",
    "    return jnp.array(eqs)\n",
    "\n",
    "# Update integral function to pass the neural network parameters\n",
    "def integral(f, t_k, t_k1, u, t_grid, params):\n",
    "    integrand = lambda s: f(s, interpolate(u, s, t_grid), params)\n",
    "    vectorized_integrand = jax.vmap(integrand)\n",
    "    s_values = jnp.linspace(t_k, t_k1, 100)\n",
    "    integrand_values = vectorized_integrand(s_values)\n",
    "    integral_value = jnp.trapezoid(integrand_values, s_values, axis=0)\n",
    "    return integral_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Newton's method did not converge",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m uv_init \u001b[38;5;241m=\u001b[39m uv_init\u001b[38;5;241m.\u001b[39mat[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Set the initial velocity to 0\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Solve the system using the neural network\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m uv_solution_nn \u001b[38;5;241m=\u001b[39m \u001b[43mnewton_method_nn\u001b[49m\u001b[43m(\u001b[49m\u001b[43muv_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneural_net_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrained_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Print the solution\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolution at grid points using neural network:\u001b[39m\u001b[38;5;124m\"\u001b[39m, uv_solution_nn)\n",
      "Cell \u001b[0;32mIn[17], line 58\u001b[0m, in \u001b[0;36mnewton_method_nn\u001b[0;34m(u_init, t_grid, f, params, u0, tol, max_iter)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverged at iteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m u\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNewton\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms method did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Newton's method did not converge"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "T = 4.0  # End time\n",
    "N = 10  # Number of grid points\n",
    "omega = 1\n",
    "\n",
    "# Create the grid points\n",
    "interpolator = BarycentricInterpolation(N, start=0, stop=T)\n",
    "t_grid = interpolator.nodes\n",
    "\n",
    "# Initial guess for the solution\n",
    "uv_init = jnp.ones((N, 2))  # Start with a non-zero initial guess\n",
    "uv_init = uv_init.at[0, 1].set(0)  # Set the initial velocity to 0\n",
    "\n",
    "# Solve the system using the neural network\n",
    "uv_solution_nn = newton_method_nn(uv_init, t_grid, neural_net_f, trained_params)\n",
    "\n",
    "# Print the solution\n",
    "print(\"Solution at grid points using neural network:\", uv_solution_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs. true solution\n",
    "true_solution_u = jnp.cos(omega * t_grid)\n",
    "true_solution_v = -omega * jnp.sin(omega * t_grid)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(t_grid, uv_solution_nn[:, 0], 'ro-', label='Predicted Solution u(t)')\n",
    "plt.plot(t_grid, true_solution_u, 'b-', label='True Solution u(t)')\n",
    "plt.plot(t_grid, uv_solution_nn[:, 1], 'go-', label='Predicted Solution v(t)')\n",
    "plt.plot(t_grid, true_solution_v, 'm-', label='True Solution v(t)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('u(t), v(t)')\n",
    "plt.legend()\n",
    "plt.title('Predicted vs. True Solution for Harmonic Oscillator using Neural Network')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collocation_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
