{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To do: Interpolation can be done a single time before training & function saved\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import time\n",
    "\n",
    "# stats\n",
    "from statsmodels.api import tsa # time series analysis\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# interpolation\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "# pre-processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# collocation\n",
    "import sys\n",
    "import os\n",
    "p_ = os.path.abspath(os.path.join('..', '00_utils'))\n",
    "if p_ not in sys.path:\n",
    "    sys.path.append(p_)\n",
    "    \n",
    "p_ = os.path.abspath(os.path.join('..', '00_models'))\n",
    "if p_ not in sys.path:\n",
    "    sys.path.append(p_)\n",
    "\n",
    "import preprocess # helper preprocessing class\n",
    "\n",
    "# pyomo\n",
    "import importlib\n",
    "import nn_jax_diffrax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To do: Interpolation can be done a single time before training & function saved\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(nn_jax_diffrax)\n",
    "NeuralODE_JAX = nn_jax_diffrax.NeuralODE\n",
    "\n",
    "importlib.reload(preprocess)\n",
    "DataPreprocessor = preprocess.DataPreprocessor\n",
    "\n",
    "# , 'temperature': 'var1'\n",
    "file_path = '../00_data/df_train.csv'\n",
    "encoding = {'settlement_date': 't', 'temperature': 'var1', 'hour': 'var2', 'nd': 'y'}\n",
    "\n",
    "layer_widths = [7, 65, 65, 1]\n",
    "learning_rate = 1e-3\n",
    "rng = random.PRNGKey(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2015-01-10', '2015-01-15', '2015-01-20', '2015-01-25', '2015-01-30', '2015-02-04', '2015-02-09', '2015-02-14', '2015-02-19', '2015-02-24']\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# prepare data ranges\n",
    "START_DATE = '2015-01-10'\n",
    "start_date = datetime.strptime(START_DATE, '%Y-%m-%d')\n",
    "date_sequences = [start_date + timedelta(days=i*5) for i in range(10)]\n",
    "date_sequences_str = [date.strftime('%Y-%m-%d') for date in date_sequences]\n",
    "print(date_sequences_str)\n",
    "\n",
    "times_elapsed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Loss: 0.8166288733482361\n",
      "Epoch 200, Loss: 0.6926212310791016\n",
      "Epoch 300, Loss: 0.6371097564697266\n",
      "Epoch 400, Loss: 0.6148166656494141\n",
      "Epoch 500, Loss: 0.5973230004310608\n",
      "Epoch 600, Loss: 0.6010914444923401\n",
      "Epoch 700, Loss: 0.5636014938354492\n",
      "Epoch 800, Loss: 0.5443029403686523\n",
      "Epoch 900, Loss: 0.5165137052536011\n",
      "Epoch 1000, Loss: 0.4992322027683258\n",
      "Epoch 100, Loss: 0.9511800408363342\n",
      "Epoch 200, Loss: 0.7797123789787292\n",
      "Epoch 300, Loss: 0.6828694343566895\n",
      "Epoch 400, Loss: 0.5641154646873474\n",
      "Epoch 500, Loss: 0.45781856775283813\n",
      "Epoch 600, Loss: 0.38864433765411377\n",
      "Epoch 700, Loss: 0.34057408571243286\n",
      "Epoch 800, Loss: 0.30896252393722534\n",
      "Epoch 900, Loss: 0.28064948320388794\n",
      "Epoch 1000, Loss: 0.28121814131736755\n",
      "Epoch 100, Loss: 0.9835340976715088\n",
      "Epoch 200, Loss: 0.7612800002098083\n",
      "Epoch 300, Loss: 0.6586185097694397\n",
      "Epoch 400, Loss: 0.5834441781044006\n",
      "Epoch 500, Loss: 0.5397061705589294\n",
      "Epoch 600, Loss: 0.49830663204193115\n",
      "Epoch 700, Loss: 0.46874141693115234\n",
      "Epoch 800, Loss: 0.43215039372444153\n",
      "Epoch 900, Loss: 0.3949880003929138\n",
      "Epoch 1000, Loss: 0.3427872955799103\n",
      "Epoch 100, Loss: 0.847293496131897\n",
      "Epoch 200, Loss: 0.7196024060249329\n",
      "Epoch 300, Loss: 0.6610207557678223\n",
      "Epoch 400, Loss: 0.6343667507171631\n",
      "Epoch 500, Loss: 0.6089078783988953\n",
      "Epoch 600, Loss: 0.6058993339538574\n",
      "Epoch 700, Loss: 0.5393294095993042\n",
      "Epoch 800, Loss: 0.5023519396781921\n",
      "Epoch 900, Loss: 0.46405625343322754\n",
      "Epoch 1000, Loss: 0.4245983064174652\n",
      "Epoch 100, Loss: 0.9814025163650513\n",
      "Epoch 200, Loss: 0.7229851484298706\n",
      "Epoch 300, Loss: 0.60988450050354\n",
      "Epoch 400, Loss: 0.5613422393798828\n",
      "Epoch 500, Loss: 0.538268506526947\n",
      "Epoch 600, Loss: 0.5054299831390381\n",
      "Epoch 700, Loss: 0.4662293791770935\n",
      "Epoch 800, Loss: 0.43881934881210327\n",
      "Epoch 900, Loss: 0.419744610786438\n",
      "Epoch 1000, Loss: 0.409790962934494\n",
      "Epoch 100, Loss: 0.9881560206413269\n",
      "Epoch 200, Loss: 0.7438793182373047\n",
      "Epoch 300, Loss: 0.6238894462585449\n",
      "Epoch 400, Loss: 0.5388510823249817\n",
      "Epoch 500, Loss: 0.46448153257369995\n",
      "Epoch 600, Loss: 0.4064961075782776\n",
      "Epoch 700, Loss: 0.3586701452732086\n",
      "Epoch 800, Loss: 0.32819971442222595\n",
      "Epoch 900, Loss: 0.30067119002342224\n",
      "Epoch 1000, Loss: 0.27239400148391724\n",
      "Epoch 100, Loss: 1.0562596321105957\n",
      "Epoch 200, Loss: 0.8419514298439026\n",
      "Epoch 300, Loss: 0.7047996520996094\n",
      "Epoch 400, Loss: 0.6333332657814026\n",
      "Epoch 500, Loss: 0.5951642990112305\n",
      "Epoch 600, Loss: 0.5653297901153564\n",
      "Epoch 700, Loss: 0.5394802093505859\n",
      "Epoch 800, Loss: 0.5240789651870728\n",
      "Epoch 900, Loss: 0.5322071313858032\n",
      "Epoch 1000, Loss: 0.5173242092132568\n",
      "Epoch 100, Loss: 0.8881533741950989\n",
      "Epoch 200, Loss: 0.750119149684906\n",
      "Epoch 300, Loss: 0.7212437987327576\n",
      "Epoch 400, Loss: 0.6747974157333374\n",
      "Epoch 500, Loss: 0.6412617564201355\n",
      "Epoch 600, Loss: 0.595547616481781\n",
      "Epoch 700, Loss: 0.5567129254341125\n",
      "Epoch 800, Loss: 0.5197691917419434\n",
      "Epoch 900, Loss: 0.4840770959854126\n",
      "Epoch 1000, Loss: 0.44183528423309326\n",
      "Epoch 100, Loss: 0.9776415824890137\n",
      "Epoch 200, Loss: 0.7459833025932312\n",
      "Epoch 300, Loss: 0.5829615592956543\n",
      "Epoch 400, Loss: 0.4778737723827362\n",
      "Epoch 500, Loss: 0.39765849709510803\n",
      "Epoch 600, Loss: 0.34005099534988403\n",
      "Epoch 700, Loss: 0.29554039239883423\n",
      "Epoch 800, Loss: 0.2609351873397827\n",
      "Epoch 900, Loss: 0.2308209240436554\n",
      "Epoch 1000, Loss: 0.20640337467193604\n",
      "Epoch 100, Loss: 1.0163519382476807\n",
      "Epoch 200, Loss: 0.8228805661201477\n",
      "Epoch 300, Loss: 0.7401587963104248\n",
      "Epoch 400, Loss: 0.6686652302742004\n",
      "Epoch 500, Loss: 0.5935907363891602\n",
      "Epoch 600, Loss: 0.5238119959831238\n",
      "Epoch 700, Loss: 0.46155765652656555\n",
      "Epoch 800, Loss: 0.41545116901397705\n",
      "Epoch 900, Loss: 0.37400561571121216\n",
      "Epoch 1000, Loss: 0.34471815824508667\n"
     ]
    }
   ],
   "source": [
    "experiment_results = {}\n",
    "\n",
    "for START_DATE in date_sequences_str:\n",
    "    data_loader = DataPreprocessor(file_path, start_date = START_DATE, number_of_points = 400, n_days = 1, m = 1, \n",
    "                                   feature_encoding = encoding, split = 200, equally_spaced = True, \n",
    "                                   smooth = False, num_nodes_mult = 1)\n",
    "    \n",
    "    data_subsample = data_loader.load_data()\n",
    "    df_train, df_test = data_loader.preprocess_data(data_subsample)\n",
    "\n",
    "    node_model = NeuralODE_JAX(layer_widths, time_invariant=True)\n",
    "    state = node_model.create_train_state(rng, learning_rate)\n",
    "\n",
    "    ys = jnp.atleast_2d(jnp.array(df_train['y'])).T\n",
    "    ts = jnp.array(df_train['t'])\n",
    "    Xs = jnp.array(df_train.drop(columns=['y', 't']))\n",
    "    extra_args = (Xs, ts)\n",
    "    y0 = jnp.array(ys[0])\n",
    "\n",
    "    start_time = time.time()\n",
    "    state = node_model.train(state, ts[:] \n",
    "                            , ys[:], y0\n",
    "                            , num_epochs = 1000\n",
    "                            , extra_args = extra_args[:]\n",
    "                            )\n",
    "    end_time = time.time()\n",
    "    \n",
    "    y_train_pred = node_model.neural_ode(state.params, y0, ts, state, extra_args)\n",
    "    \n",
    "    experiment_results[START_DATE] = {}\n",
    "    experiment_results[START_DATE]['times_elapsed'] = end_time - start_time\n",
    "    \n",
    "    experiment_results[START_DATE]['mae_diffrax'] = np.mean(np.abs(np.squeeze(y_train_pred) - np.squeeze(ys)))\n",
    "    experiment_results[START_DATE]['mse_diffrax'] = np.mean(np.square(np.squeeze(y_train_pred) - np.squeeze(ys)))\n",
    "    # -------------------------------------------- DIFFRAX NODE PREDICTION (TRAIN) --------------------\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(ts, ys, 'r--', label='True Data')  \n",
    "    plt.plot(ts, np.squeeze(y_train_pred), 'b' ,label='Predicted Data') \n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('u(t)')\n",
    "    plt.title(f\"Diffrax Neural ODE - Train Data\")\n",
    "    plt.legend(loc =\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'plots/diffrax/diffrax_solver_train_{START_DATE}.png', format='png')  \n",
    "    plt.close() \n",
    "\n",
    "    # -------------------------------------------- DIFFRAX NODE PREDICTION (TEST) --------------------\n",
    "    ys_test = jnp.atleast_2d(jnp.array(df_test['y'])).T\n",
    "    ts_test = jnp.array(df_test['t'])\n",
    "    Xs_test = jnp.array(df_test.drop(columns=['y', 't']))\n",
    "    extra_args_test = (Xs_test, ts_test)\n",
    "    y0_test = jnp.array(ys_test[0])\n",
    "    \n",
    "    y_test_pred = node_model.neural_ode(state.params, y0_test, ts_test, state, extra_args_test)\n",
    "    \n",
    "    experiment_results[START_DATE]['mae_diffrax_test'] = np.mean(np.abs(np.squeeze(y_test_pred) - np.squeeze(ys_test)))\n",
    "    experiment_results[START_DATE]['mse_diffrax_test'] = np.mean(np.square(np.squeeze(y_test_pred) - np.squeeze(ys_test)))\n",
    "    \n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(ts_test, ys_test, 'r--', label='True Data (Test)')  \n",
    "    plt.plot(ts_test, np.squeeze(y_test_pred), 'b' ,label='Predicted Data (Test)') \n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('u(t)')\n",
    "    plt.title(f\"Diffrax Neural ODE - Test Data\")\n",
    "    plt.legend(loc =\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'plots/diffrax/diffrax_solver_test_{START_DATE}.png', format='png')  \n",
    "    plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'times_elapsed': 4.602709054946899,\n",
       " 'mae_diffrax': 0.5773487,\n",
       " 'mse_diffrax': 0.49768555,\n",
       " 'mae_diffrax_test': 1.6517676,\n",
       " 'mse_diffrax_test': 3.3748527}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_results['2015-01-10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train: 0.501\n",
      "MAE test: 1.21\n",
      "MSE train: 0.371\n",
      "MSE test: 2.51\n",
      "Avg sovler time elapsed: 5.15 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f\"MAE train: {np.mean([experiment_results[k]['mae_diffrax'] for k in experiment_results.keys()]):.3f}\")\n",
    "print(f\"MAE test: {np.mean([experiment_results[k]['mae_diffrax_test'] for k in experiment_results.keys()]):.3}\")\n",
    "print(f\"MSE train: {np.mean([experiment_results[k]['mse_diffrax'] for k in experiment_results.keys()]):.3f}\")\n",
    "print(f\"MSE test: {np.mean([experiment_results[k]['mse_diffrax_test'] for k in experiment_results.keys()]):.3}\")\n",
    "print(f\"Avg sovler time elapsed: {np.mean([experiment_results[k]['times_elapsed'] for k in experiment_results.keys()]):.3} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00001\n"
     ]
    }
   ],
   "source": [
    "print(f\"{1e-5:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collocation_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
