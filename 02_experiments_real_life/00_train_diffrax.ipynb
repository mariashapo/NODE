{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# jax\n",
    "import jax.numpy as jnp\n",
    "import time\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "def append_path(path):\n",
    "    if path not in sys.path:\n",
    "        sys.path.append(path)\n",
    "\n",
    "def reload_module(module_name, class_name):\n",
    "    module = importlib.import_module(module_name)\n",
    "    importlib.reload(module)\n",
    "    return getattr(module, class_name)\n",
    "        \n",
    "append_path(os.path.abspath(os.path.join('..', '00_utils')))\n",
    "append_path(os.path.abspath(os.path.join('..', '00_utils_training')))\n",
    "append_path(os.path.abspath(os.path.join('..', '00_models')))\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR, filename='error_log.txt')\n",
    "\n",
    "import optimize_diffrax_rl\n",
    "\n",
    "ExperimentRunner = reload_module('optimize_diffrax_rl', 'ExperimentRunner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../00_trained_wb/rl_32_weights_2024-09-02_11-32-54.pkl'\n",
    "path = '../00_trained_wb/trained_wb_2024-09-02_14-40-45.pkl'\n",
    "# import trained weights\n",
    "with open(path, 'rb') as file:\n",
    "    trained_wb = pickle.load(file)\n",
    "    \n",
    "trained_wb = ExperimentRunner.format_weights_from_pyomo(trained_wb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating default parameters for data\n",
      "Generating default parameters for model\n",
      "Running iteration 1 with parameters: 1\n",
      "Start Data: 2015-01-10 00:00:00\n",
      "days_offset: 1\n",
      "Offset: 2015-01-09 00:00:00\n",
      "Epoch 100, Loss: 0.5808260649058886\n",
      "Epoch 200, Loss: 0.2611207497737063\n",
      "Epoch 300, Loss: 0.15181834528485907\n",
      "Epoch 400, Loss: 0.09622062042604294\n",
      "Epoch 500, Loss: 0.07358478881024964\n",
      "Epoch 600, Loss: 0.058200305890362965\n",
      "Epoch 700, Loss: 0.06254173408365848\n",
      "Epoch 800, Loss: 0.06679710072977299\n",
      "Epoch 900, Loss: 0.05095791189409308\n",
      "Epoch 1000, Loss: 0.04990359369442999\n",
      "Epoch 1100, Loss: 0.042075525415067115\n",
      "Epoch 1200, Loss: 0.07182199174888158\n",
      "Epoch 1300, Loss: 0.09213322938268506\n",
      "Epoch 1400, Loss: 0.050988476420629036\n",
      "Epoch 1500, Loss: 0.044300226467768905\n",
      "Epoch 1600, Loss: 0.03908287598436878\n",
      "Epoch 1700, Loss: 0.03570385412060241\n",
      "Epoch 1800, Loss: 0.036795350863467594\n",
      "Epoch 1900, Loss: 0.054972452330798366\n",
      "Epoch 2000, Loss: 0.08542006668878481\n",
      "Epoch 2100, Loss: 0.03662204332955993\n",
      "Epoch 2200, Loss: 0.03256807558900321\n",
      "Epoch 2300, Loss: 0.032314501167463774\n",
      "Epoch 2400, Loss: 0.03051046662255777\n",
      "Epoch 2500, Loss: 0.030633235944326414\n",
      "Epoch 2600, Loss: 0.028225633742438933\n",
      "Epoch 2700, Loss: 0.026715930842732362\n",
      "Epoch 2800, Loss: 0.02667693610393728\n",
      "Epoch 2900, Loss: 0.031999283312409976\n",
      "Epoch 3000, Loss: 0.02470789750964537\n",
      "Epoch 3100, Loss: 0.02100513703471446\n",
      "Epoch 3200, Loss: 0.0193036076993663\n",
      "Epoch 3300, Loss: 0.0178657799701033\n",
      "Epoch 3400, Loss: 0.01750051926890367\n",
      "Epoch 3500, Loss: 0.01688368602782904\n",
      "Epoch 3600, Loss: 0.016312437542123984\n",
      "Epoch 3700, Loss: 0.016053625799149655\n",
      "Epoch 3800, Loss: 0.015353049293036415\n",
      "Epoch 3900, Loss: 0.015239269576832162\n",
      "Epoch 4000, Loss: 0.014676741867470484\n",
      "Epoch 4100, Loss: 0.015858879303689212\n",
      "Epoch 4200, Loss: 0.015751803871174017\n",
      "Epoch 4300, Loss: 0.014156341946795704\n",
      "Epoch 4400, Loss: 0.016261785486837155\n",
      "Epoch 4500, Loss: 0.014222031011691085\n",
      "Epoch 4600, Loss: 0.015697516936937855\n",
      "Epoch 4700, Loss: 0.013799465536928936\n",
      "Epoch 4800, Loss: 0.014186253489697018\n",
      "Epoch 4900, Loss: 0.016595526854036705\n",
      "Epoch 5000, Loss: 0.018363012807786884\n",
      "Epoch 5100, Loss: 0.012931493699230691\n",
      "Epoch 5200, Loss: 0.013058414044997885\n",
      "Epoch 5300, Loss: 0.01462334318043218\n",
      "Epoch 5400, Loss: 0.013256567963487384\n",
      "Epoch 5500, Loss: 0.01596057718361258\n",
      "Epoch 5600, Loss: 0.01421784661041475\n",
      "Epoch 5700, Loss: 0.01314450933396906\n",
      "Epoch 5800, Loss: 0.01701849164201067\n",
      "Epoch 5900, Loss: 0.013391464614983414\n",
      "Epoch 6000, Loss: 0.012546120616245451\n",
      "Epoch 6100, Loss: 0.012133875640076246\n",
      "Epoch 6200, Loss: 0.012079182298816181\n",
      "Epoch 6300, Loss: 0.012204005625626966\n",
      "Epoch 6400, Loss: 0.01210204851491806\n",
      "Epoch 6500, Loss: 0.011810348179383198\n",
      "Epoch 6600, Loss: 0.02332811908062931\n",
      "Epoch 6700, Loss: 0.011992996043256177\n",
      "Epoch 6800, Loss: 0.01208608010821574\n",
      "Epoch 6900, Loss: 0.013592358270291737\n",
      "Epoch 7000, Loss: 0.012029385258952556\n",
      "Epoch 7100, Loss: 0.012070457056611902\n",
      "Epoch 7200, Loss: 0.011791261614582917\n",
      "Epoch 7300, Loss: 0.01201862311248079\n",
      "Epoch 7400, Loss: 0.011728076187145376\n",
      "Epoch 7500, Loss: 0.013317693214542937\n",
      "Epoch 7600, Loss: 0.01145680581262821\n",
      "Epoch 7700, Loss: 0.011608887621841424\n",
      "Epoch 7800, Loss: 0.019557507736604758\n",
      "Epoch 7900, Loss: 0.01886059925454283\n",
      "Epoch 8000, Loss: 0.01400177712402836\n",
      "Epoch 8100, Loss: 0.013399343200336995\n",
      "Epoch 8200, Loss: 0.01286086312077784\n",
      "Epoch 8300, Loss: 0.015287783765922432\n",
      "Epoch 8400, Loss: 0.01306040150720874\n",
      "Epoch 8500, Loss: 0.013336925252821822\n",
      "Epoch 8600, Loss: 0.013091782859271962\n",
      "Epoch 8700, Loss: 0.014986234065011284\n",
      "Epoch 8800, Loss: 0.012823024467928651\n",
      "Epoch 8900, Loss: 0.012085094917594626\n",
      "Epoch 9000, Loss: 0.011818302443227218\n",
      "Epoch 9100, Loss: 0.011885915648745067\n",
      "Epoch 9200, Loss: 0.013791536232011441\n",
      "Epoch 9300, Loss: 0.011617079123379444\n",
      "Epoch 9400, Loss: 0.011328746632504057\n",
      "Epoch 9500, Loss: 0.011214310975164232\n",
      "Epoch 9600, Loss: 0.013618340254042103\n",
      "Epoch 9700, Loss: 0.016884138095290928\n",
      "Epoch 9800, Loss: 0.011509180982583961\n",
      "Epoch 9900, Loss: 0.011676076049054004\n",
      "Epoch 10000, Loss: 0.010929848107696632\n",
      "Epoch 10100, Loss: 0.011051974055892793\n",
      "Epoch 10200, Loss: 0.011658168868491196\n",
      "Epoch 10300, Loss: 0.011382064378239277\n",
      "Epoch 10400, Loss: 0.010863202168470103\n",
      "Epoch 10500, Loss: 0.010812966118257447\n",
      "Epoch 10600, Loss: 0.01245912117832661\n",
      "Epoch 10700, Loss: 0.010858970536387265\n",
      "Epoch 10800, Loss: 0.0124404045225668\n",
      "Epoch 10900, Loss: 0.011440762326598358\n",
      "Epoch 11000, Loss: 0.012222255864758164\n",
      "Epoch 11100, Loss: 0.010936853028622325\n",
      "Epoch 11200, Loss: 0.025834872846473782\n",
      "Epoch 11300, Loss: 0.012313928935435349\n",
      "Epoch 11400, Loss: 0.01842759434655605\n",
      "Epoch 11500, Loss: 0.011112161448075402\n",
      "Epoch 11600, Loss: 0.012955162800512506\n",
      "Epoch 11700, Loss: 0.011402603671295822\n",
      "Epoch 11800, Loss: 0.012184811708671299\n",
      "Epoch 11900, Loss: 0.013259741547912865\n",
      "Epoch 12000, Loss: 0.010807276043713912\n",
      "Epoch 12100, Loss: 0.011144718663556517\n",
      "Epoch 12200, Loss: 0.012074079741168822\n",
      "Epoch 12300, Loss: 0.011349945868342056\n",
      "Epoch 12400, Loss: 0.020005918018901565\n",
      "Epoch 12500, Loss: 0.011674115709170537\n",
      "Epoch 12600, Loss: 0.018067067168190558\n",
      "Epoch 12700, Loss: 0.011804928199353595\n",
      "Epoch 12800, Loss: 0.01112570412772247\n",
      "Epoch 12900, Loss: 0.010988990683057542\n",
      "Epoch 13000, Loss: 0.011350516594441123\n",
      "Epoch 13100, Loss: 0.013735147523763726\n",
      "Epoch 13200, Loss: 0.011265217332773074\n",
      "Epoch 13300, Loss: 0.010997199196720136\n",
      "Epoch 13400, Loss: 0.011484487813282315\n",
      "Epoch 13500, Loss: 0.010557779921052696\n",
      "Epoch 13600, Loss: 0.010868942721728198\n",
      "Epoch 13700, Loss: 0.020465480860252613\n",
      "Epoch 13800, Loss: 0.010504981555359337\n",
      "Epoch 13900, Loss: 0.010737103231056408\n",
      "Epoch 14000, Loss: 0.011943797882745352\n",
      "Epoch 14100, Loss: 0.011109343780442652\n",
      "Epoch 14200, Loss: 0.011699077927392373\n",
      "Epoch 14300, Loss: 0.01098209552027345\n",
      "Epoch 14400, Loss: 0.011422524329745016\n",
      "Epoch 14500, Loss: 0.011514469946822996\n",
      "Epoch 14600, Loss: 0.011327846307754227\n",
      "Epoch 14700, Loss: 0.01088601871738144\n",
      "Epoch 14800, Loss: 0.010918785450748657\n",
      "Epoch 14900, Loss: 0.010846862686125436\n",
      "Epoch 15000, Loss: 0.013318362533108828\n",
      "Epoch 15100, Loss: 0.011418329232398194\n",
      "Epoch 15200, Loss: 0.010636686282955252\n",
      "Epoch 15300, Loss: 0.010609854091387818\n",
      "Epoch 15400, Loss: 0.010758568850588273\n",
      "Epoch 15500, Loss: 0.010575503489235926\n",
      "Epoch 15600, Loss: 0.017030744228678108\n",
      "Epoch 15700, Loss: 0.010673144750691229\n",
      "Epoch 15800, Loss: 0.010993545823915127\n",
      "Epoch 15900, Loss: 0.010675893637521972\n",
      "Epoch 16000, Loss: 0.011238155946234915\n",
      "Epoch 16100, Loss: 0.012046512926453104\n",
      "Epoch 16200, Loss: 0.011958609069069556\n",
      "Epoch 16300, Loss: 0.011088185370172083\n",
      "Epoch 16400, Loss: 0.012020502450132253\n",
      "Epoch 16500, Loss: 0.011287922596614671\n",
      "Epoch 16600, Loss: 0.010651364637855026\n",
      "Epoch 16700, Loss: 0.010620174247267338\n",
      "Epoch 16800, Loss: 0.010980676789519745\n",
      "Epoch 16900, Loss: 0.01373962122331411\n",
      "Epoch 17000, Loss: 0.010715047109447259\n",
      "Epoch 17100, Loss: 0.014323259567423231\n",
      "Epoch 17200, Loss: 0.010848642267155116\n",
      "Epoch 17300, Loss: 0.010634771917011981\n",
      "Epoch 17400, Loss: 0.013943455044744119\n",
      "Epoch 17500, Loss: 0.012086742642409564\n",
      "Epoch 17600, Loss: 0.014727198858498856\n",
      "Epoch 17700, Loss: 0.011492828062576036\n",
      "Epoch 17800, Loss: 0.012197698156828533\n",
      "Epoch 17900, Loss: 0.018138297253751108\n",
      "Epoch 18000, Loss: 0.011715781108942221\n",
      "Epoch 18100, Loss: 0.01204478669515897\n",
      "Epoch 18200, Loss: 0.011317879509658475\n",
      "Epoch 18300, Loss: 0.010898740625187519\n",
      "Epoch 18400, Loss: 0.010878227086193105\n",
      "Epoch 18500, Loss: 0.010904964324830554\n",
      "Epoch 18600, Loss: 0.011501012850453261\n",
      "Epoch 18700, Loss: 0.011070906150046642\n",
      "Epoch 18800, Loss: 0.010910451583637302\n",
      "Epoch 18900, Loss: 0.013000865549806923\n",
      "Epoch 19000, Loss: 0.02535257728528802\n",
      "Epoch 19100, Loss: 0.012140052711594754\n",
      "Epoch 19200, Loss: 0.010950399961330338\n",
      "Epoch 19300, Loss: 0.010918959504810092\n",
      "Epoch 19400, Loss: 0.011639701947329752\n",
      "Epoch 19500, Loss: 0.010420970363617634\n",
      "Epoch 19600, Loss: 0.010497754249876222\n",
      "Epoch 19700, Loss: 0.02762330252183485\n",
      "Epoch 19800, Loss: 0.01906901797258475\n",
      "Epoch 19900, Loss: 0.01632930103629192\n",
      "Epoch 20000, Loss: 0.015778566418733722\n",
      "Iteration i: 1/1 completed\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(optimize_diffrax_rl)\n",
    "ExperimentRunner = optimize_diffrax_rl.ExperimentRunner\n",
    "start_date = '2015-01-10'\n",
    "\n",
    "extra_inputs = {}\n",
    "extra_inputs['params_model'] = {'layer_sizes': [7, 32, 32, 1], 'penalty': 1e-5, 'learning_rate': 1e-2, 'num_epochs': 20000, 'pretrain': False}\n",
    "\n",
    "extra_inputs['params_data'] = {'file_path': '../00_data/df_train.csv', 'start_date': start_date, \n",
    "                'n_points': 300, 'split': 200, 'n_days': 1, 'm': 1, \n",
    "                'prev_hour': False, 'prev_week': True, 'prev_year': True,\n",
    "                'spacing': 'uniform',\n",
    "                'encoding': {'settlement_date': 't', 'temperature': 'var1', 'hour': 'var2', 'nd': 'y'}}\n",
    "\n",
    "extra_inputs['params_sequence'] = {'sequence_len': 1, 'frequency': 35}\n",
    "extra_inputs['params_results'] = {'plot':True, 'log' : False, 'split_time' : False}\n",
    "#extra_inputs['trained_wb'] = trained_wb\n",
    "\n",
    "runner = ExperimentRunner(start_date, 'default', extra_inputs)\n",
    "runner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'times_elapsed': 65.04188876152038,\n",
       "  'mse_diffrax': 0.003666992289213589,\n",
       "  'mse_diffrax_test': 0.31264357364636086}}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.results_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results/short_training_10_jax_2024-09-08_13-37-55_full.pkl\n",
      "Results saved to results/short_training_10_jax_2024-09-08_13-37-55_avg.pkl\n"
     ]
    }
   ],
   "source": [
    "runner.save_results('short_training_10_jax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'results/convergence_jax_no_pretrain_2024-09-02_18-25-17_full.pkl'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collocation_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
