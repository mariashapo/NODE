{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# -------------- helper libraries -------------- #\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import itertools\n",
    "\n",
    "def append_path(path):\n",
    "    if path not in sys.path:\n",
    "        sys.path.append(path)\n",
    "\n",
    "append_path(os.path.abspath(os.path.join('..', '00_utils')))\n",
    "append_path(os.path.abspath(os.path.join('..', '00_utils_training')))\n",
    "append_path(os.path.abspath(os.path.join('..', '00_models')))\n",
    "\n",
    "import run_train_toy\n",
    "importlib.reload(run_train_toy)\n",
    "Trainer = run_train_toy.TrainerToy\n",
    "\n",
    "import analyse_results\n",
    "reload_module = analyse_results.reload_module\n",
    "\n",
    "Graphs = reload_module('analyse_results', 'Graphs')\n",
    "Results = reload_module('analyse_results', 'Results')\n",
    "convert_lists_in_tuple = reload_module('analyse_results', 'convert_lists_in_tuple')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR, filename='error_log.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1e-05, 500)\n",
      "reg: 1e-05 max_iter: 500\n",
      "(1e-05, 1000)\n",
      "reg: 1e-05 max_iter: 1000\n",
      "(1e-05, 1500)\n",
      "reg: 1e-05 max_iter: 1500\n",
      "(0.0001, 500)\n",
      "reg: 0.0001 max_iter: 500\n",
      "(0.0001, 1000)\n",
      "reg: 0.0001 max_iter: 1000\n",
      "(0.0001, 1500)\n",
      "reg: 0.0001 max_iter: 1500\n",
      "(0.001, 500)\n",
      "reg: 0.001 max_iter: 500\n",
      "(0.001, 1000)\n",
      "reg: 0.001 max_iter: 1000\n",
      "(0.001, 1500)\n",
      "reg: 0.001 max_iter: 1500\n"
     ]
    }
   ],
   "source": [
    "reg_list = [1e-5, 1e-4, 1e-3]\n",
    "max_iter_li = [500, 1000, 1500]\n",
    "\n",
    "param_combinations = list(itertools.product(reg_list, max_iter_li))\n",
    "\n",
    "for c in param_combinations:\n",
    "    print(str(c))\n",
    "    print(\"reg:\", c[0], \"max_iter:\", c[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(optimization_type):\n",
    "  TRAINER = Trainer.load_trainer(\"ho\", spacing_type = \"uniform\", model_type = \"jax_diffrax\") \n",
    "  results = {}\n",
    "  AVERAGED = False\n",
    "\n",
    "  #optimization_type = 'activation'\n",
    "\n",
    "  params_model = {\n",
    "      'layer_widths': [2, 32, 2],\n",
    "      'penalty_lambda_reg': 1e-3,\n",
    "      'time_invariant': True,\n",
    "      'learning_rate': 1e-3,\n",
    "      'max_iter': [1000, 5000],\n",
    "      'pretrain': [0.2, 1],\n",
    "      'verbose': False,\n",
    "      'rtol': 1e-3,\n",
    "      'atol': 1e-6,\n",
    "      \"log\": False,\n",
    "      'act_func': 'tanh',\n",
    "      'split_time': False\n",
    "  }\n",
    "\n",
    "  if optimization_type == 'network_size':\n",
    "    lw = [[2, 8, 2], [2, 16, 2], [2, 32, 2], [2, 16, 16, 2], [2, 32, 32, 2]]\n",
    "    # lw = [[2, 16, 2], [2, 32, 2], [2, 64, 2], [2, 128, 2]]\n",
    "    reg_list = [1e-5, 1e-4, 1e-3]\n",
    "    max_iter_li = [[1000, 5000], [1000, 7500], [1000, 10000]]\n",
    "    param_combinations = list(itertools.product(lw, reg_list, max_iter_li))\n",
    "  elif optimization_type == 'tolerance':\n",
    "    rtol = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    atol = [1e-3, 1e-4, 1e-5, 1e-6, 1e-7]\n",
    "    param_combinations = list(itertools.product(rtol, atol))\n",
    "  elif optimization_type == 'none':\n",
    "    param_combinations = [0]\n",
    "  elif optimization_type == 'activation':\n",
    "    act = ['tanh', 'relu', 'sigmoid']\n",
    "    data = ['vdp', 'ho', 'do']\n",
    "    param_combinations = list(itertools.product(act, data))\n",
    "  elif optimization_type == 'training_convergence':\n",
    "    data = ['ho', 'vdp', 'do']\n",
    "    pretrain = [False, [0.2, 1]]\n",
    "    params_model['log'] = 1000\n",
    "    #params_model['log'] = False #50 \n",
    "    #params_model['split_time'] = True\n",
    "    param_combinations = list(itertools.product(data, pretrain))\n",
    "  elif optimization_type == 'regularization':\n",
    "    reg_list = [0, 1e-06, 1.0e-04, 1.0e-03, 1.0e-02, 1.0e-01,1]\n",
    "    param_combinations = reg_list\n",
    "  else:\n",
    "    raise ValueError(\"Invalid optimization type\")\n",
    "\n",
    "  total_iter = len(param_combinations)\n",
    "  i = 1\n",
    "\n",
    "  for param_comb in param_combinations:\n",
    "      if optimization_type == 'network_size':\n",
    "        lw = param_comb[0]\n",
    "        params_model['layer_widths'] = lw\n",
    "        params_model['penalty_lambda_reg'] = param_comb[1]\n",
    "        params_model['max_iter'] = param_comb[2]\n",
    "      \n",
    "      elif optimization_type == 'regularization':\n",
    "        params_model['penalty_lambda_reg'] = param_comb\n",
    "        \n",
    "      elif optimization_type == 'tolerance':\n",
    "        params_model['rtol'] = param_comb[0]\n",
    "        params_model['atol'] = param_comb[1]\n",
    "        \n",
    "      elif optimization_type == 'activation':\n",
    "        params_model['act_func'] = param_comb[0]\n",
    "        TRAINER = Trainer.load_trainer(param_comb[1], spacing_type = \"uniform\", model_type = \"jax_diffrax\") \n",
    "        \n",
    "      elif optimization_type == 'training_convergence':\n",
    "          TRAINER = Trainer.load_trainer(param_comb[0], spacing_type = \"uniform\", model_type = \"jax_diffrax\") \n",
    "          params_model['pretrain'] = param_comb[1]\n",
    "          # params_model['log'] = True\n",
    "          if params_model['pretrain'] == False:\n",
    "              params_model['max_iter'] = 30000\n",
    "          else:\n",
    "              params_model['max_iter'] = [1000, 30000]\n",
    "      else:\n",
    "        if optimization_type != 'none':\n",
    "          raise ValueError(\"Invalid optimization type\")\n",
    "        else:\n",
    "          params_model['log'] = True\n",
    "      \n",
    "      print(params_model['log'])\n",
    "      if not AVERAGED:\n",
    "        try:\n",
    "          TRAINER.train(params_model)\n",
    "        except Exception as e:\n",
    "          print(\"Failed to complete training: {}\".format(e))\n",
    "          logging.error(\"Failed to complete training: {}\".format(e))\n",
    "          continue\n",
    "        \n",
    "        if isinstance(param_comb, tuple):\n",
    "          param_comb = convert_lists_in_tuple(param_comb)\n",
    "        result = TRAINER.extract_results()\n",
    "        print(param_comb)\n",
    "        \n",
    "        if optimization_type == 'training_convergence':\n",
    "          param_comb = (param_comb[0], True if param_comb[1] else False)\n",
    "          \n",
    "        results[param_comb] = result\n",
    "        \n",
    "        if optimization_type == 'training_convergence':\n",
    "            training_loss = TRAINER.losses\n",
    "            results[param_comb]['training_loss'] = training_loss\n",
    "        \n",
    "        print(results[param_comb]['mse_train'])\n",
    "        print(results[param_comb]['mse_test'])\n",
    "        print(results[param_comb]['time_elapsed'])\n",
    "        \n",
    "      if AVERAGED:\n",
    "        mse_train = []\n",
    "        mse_test = []\n",
    "        time_elapsed = []\n",
    "        for _ in range(5):\n",
    "          try:\n",
    "            TRAINER.train(params_model)\n",
    "          except Exception as e:\n",
    "            print(\"Failed to complete training: {}\".format(e))\n",
    "            logging.error(\"Failed to complete training: {}\".format(e))\n",
    "            continue\n",
    "            \n",
    "          result = TRAINER.extract_results()\n",
    "          mse_train.append(result['mse_train'])\n",
    "          mse_test.append(result['mse_test'])\n",
    "          time_elapsed.append(result['time_elapsed'])\n",
    "          \n",
    "        results[param_comb] = {\n",
    "            'mse_train': np.mean(mse_train),\n",
    "            'mse_test': np.mean(mse_test),\n",
    "            'time_elapsed': np.mean(time_elapsed)\n",
    "        }\n",
    "        \n",
    "        print(results[param_comb]['mse_train'])\n",
    "        print(results[param_comb]['mse_test'])\n",
    "      \n",
    "      print(\"Iteration:\", i, \"/\", total_iter)\n",
    "      i+=1\n",
    "      \n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0\n",
      "0.0005807362238536533\n",
      "0.002839467146660001\n",
      "6.474164009094238\n",
      "Iteration: 1 / 7\n",
      "False\n",
      "1e-06\n",
      "0.0005805351335806764\n",
      "0.0028393911030052707\n",
      "9.054824829101562\n",
      "Iteration: 2 / 7\n",
      "False\n",
      "0.0001\n",
      "0.0005636946629840601\n",
      "0.0028195188482113822\n",
      "6.025352954864502\n",
      "Iteration: 3 / 7\n",
      "False\n",
      "0.001\n",
      "0.0005001933289043781\n",
      "0.002514104245043799\n",
      "6.005992889404297\n",
      "Iteration: 4 / 7\n",
      "False\n",
      "0.01\n",
      "0.0008958695642470911\n",
      "0.002069021581028907\n",
      "6.002652883529663\n",
      "Iteration: 5 / 7\n",
      "False\n",
      "0.1\n",
      "0.42673512278258735\n",
      "0.5947926526669257\n",
      "5.7831830978393555\n",
      "Iteration: 6 / 7\n",
      "False\n",
      "1\n",
      "0.5204039110209011\n",
      "0.8310408361571286\n",
      "5.708235025405884\n",
      "Iteration: 7 / 7\n"
     ]
    }
   ],
   "source": [
    "RESULTS = run('regularization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results/jax_regularization_new.pkl\n"
     ]
    }
   ],
   "source": [
    "reload = True\n",
    "if reload:\n",
    "    formatted_time = time.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    filename = f'results/jax_regularization_new.pkl'\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(RESULTS, file)\n",
    "        \n",
    "    print(f\"Results saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collocation_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
