{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# -------------- helper libraries -------------- #\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import itertools\n",
    "\n",
    "def append_path(path):\n",
    "    if path not in sys.path:\n",
    "        sys.path.append(path)\n",
    "\n",
    "append_path(os.path.abspath(os.path.join('..', '00_utils')))\n",
    "append_path(os.path.abspath(os.path.join('..', '00_utils_training')))\n",
    "append_path(os.path.abspath(os.path.join('..', '00_models')))\n",
    "\n",
    "import run_train_toy\n",
    "importlib.reload(run_train_toy)\n",
    "Trainer = run_train_toy.TrainerToy\n",
    "\n",
    "import analyse_results\n",
    "reload_module = analyse_results.reload_module\n",
    "\n",
    "Graphs = reload_module('analyse_results', 'Graphs')\n",
    "Results = reload_module('analyse_results', 'Results')\n",
    "convert_lists_in_tuple = reload_module('analyse_results', 'convert_lists_in_tuple')\n",
    "Trainer = reload_module('run_train_toy', 'TrainerToy')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR, filename='error_log.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1e-05, 500)\n",
      "reg: 1e-05 max_iter: 500\n",
      "(1e-05, 1000)\n",
      "reg: 1e-05 max_iter: 1000\n",
      "(1e-05, 1500)\n",
      "reg: 1e-05 max_iter: 1500\n",
      "(0.0001, 500)\n",
      "reg: 0.0001 max_iter: 500\n",
      "(0.0001, 1000)\n",
      "reg: 0.0001 max_iter: 1000\n",
      "(0.0001, 1500)\n",
      "reg: 0.0001 max_iter: 1500\n",
      "(0.001, 500)\n",
      "reg: 0.001 max_iter: 500\n",
      "(0.001, 1000)\n",
      "reg: 0.001 max_iter: 1000\n",
      "(0.001, 1500)\n",
      "reg: 0.001 max_iter: 1500\n"
     ]
    }
   ],
   "source": [
    "reg_list = [1e-5, 1e-4, 1e-3]\n",
    "max_iter_li = [500, 1000, 1500]\n",
    "\n",
    "param_combinations = list(itertools.product(reg_list, max_iter_li))\n",
    "\n",
    "for c in param_combinations:\n",
    "    print(str(c))\n",
    "    print(\"reg:\", c[0], \"max_iter:\", c[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(optimization_type):\n",
    "  Trainer = reload_module('run_train_toy', 'TrainerToy')\n",
    "  trainer = Trainer.load_trainer(\"ho\", spacing_type = \"uniform\", model_type = \"jax_diffrax\") \n",
    "  results = {}\n",
    "  AVERAGED = False\n",
    "\n",
    "  #optimization_type = 'activation'\n",
    "\n",
    "  params_model = {\n",
    "      'layer_widths': [2, 32, 2],\n",
    "      'penalty_lambda_reg': 1e-3,\n",
    "      'time_invariant': True,\n",
    "      'learning_rate': 1e-3,\n",
    "      'max_iter': [10, 10],\n",
    "      'pretrain': [0.2, 1],\n",
    "      'verbose': True,\n",
    "      'rtol': 1e-3,\n",
    "      'atol': 1e-6,\n",
    "      \"log\": False,\n",
    "      'act_func': 'tanh',\n",
    "      'split_time': True\n",
    "  }\n",
    "\n",
    "  if optimization_type == 'network_size':\n",
    "    lw = [[2, 8, 2], [2, 16, 2], [2, 32, 2], [2, 16, 16, 2], [2, 32, 32, 2]]\n",
    "    lw = [[2, 8, 2], [2, 16, 2], [2, 32, 2], [2, 64, 2], [2, 128, 2]]\n",
    "    reg_list = [1e-5, 1e-4, 1e-3]\n",
    "    max_iter_li = [[1000, 5000], [1000, 7500], [1000, 10000]]\n",
    "    param_combinations = list(itertools.product(lw, reg_list, max_iter_li))\n",
    "  elif optimization_type == 'tolerance':\n",
    "    rtol = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    atol = [1e-3, 1e-4, 1e-5, 1e-6, 1e-7]\n",
    "    param_combinations = list(itertools.product(rtol, atol))\n",
    "  elif optimization_type == 'none':\n",
    "    param_combinations = [0]\n",
    "  elif optimization_type == 'activation':\n",
    "    act = ['tanh', 'relu', 'sigmoid']\n",
    "    data = ['vdp', 'ho', 'do']\n",
    "    param_combinations = list(itertools.product(act, data))\n",
    "  elif optimization_type == 'training_convergence':\n",
    "    data = ['ho', 'vdp', 'do']\n",
    "    data = ['vdp']\n",
    "    pretrain = [False, [0.2, 1]]\n",
    "    #params_model['log'] = 50\n",
    "    params_model['log'] = False \n",
    "    params_model['split_time'] = True\n",
    "    param_combinations = list(itertools.product(data, pretrain))\n",
    "  elif optimization_type == 'regularization':\n",
    "    reg_list = [0, 1e-06, 1.0e-04, 1.0e-03, 1.0e-02, 1.0e-01,1]\n",
    "    param_combinations = reg_list\n",
    "  elif optimization_type == 'default':\n",
    "    param_combinations = [0]\n",
    "  else:\n",
    "    raise ValueError(\"Invalid optimization type\")\n",
    "\n",
    "  total_iter = len(param_combinations)\n",
    "  i = 1\n",
    "\n",
    "  for param_comb in param_combinations:\n",
    "      if optimization_type == 'network_size':\n",
    "        lw = param_comb[0]\n",
    "        params_model['layer_widths'] = lw\n",
    "        params_model['penalty_lambda_reg'] = param_comb[1]\n",
    "        params_model['max_iter'] = param_comb[2]\n",
    "      \n",
    "      elif optimization_type == 'regularization':\n",
    "        params_model['penalty_lambda_reg'] = param_comb\n",
    "        \n",
    "      elif optimization_type == 'tolerance':\n",
    "        params_model['rtol'] = param_comb[0]\n",
    "        params_model['atol'] = param_comb[1]\n",
    "        \n",
    "      elif optimization_type == 'activation':\n",
    "        params_model['act_func'] = param_comb[0]\n",
    "        trainer = Trainer.load_trainer(param_comb[1], spacing_type = \"uniform\", model_type = \"jax_diffrax\") \n",
    "        \n",
    "      elif optimization_type == 'training_convergence':\n",
    "          trainer = Trainer.load_trainer(param_comb[0], spacing_type = \"uniform\", model_type = \"jax_diffrax\") \n",
    "          params_model['pretrain'] = param_comb[1]\n",
    "          # params_model['log'] = True\n",
    "          if params_model['pretrain'] == False:\n",
    "              params_model['max_iter'] = 50000\n",
    "              params_model['log'] = 250 if params_model['log'] else False\n",
    "          else:\n",
    "              params_model['max_iter'] = [1000, 30000]\n",
    "              params_model['log'] = 100 if params_model['log'] else False\n",
    "      else:\n",
    "        if optimization_type != 'default':\n",
    "          raise ValueError(\"Invalid optimization type\")\n",
    "        else:\n",
    "          pass\n",
    "      \n",
    "      print(params_model['log'])\n",
    "      if not AVERAGED:\n",
    "        try:\n",
    "          trainer.train(params_model)\n",
    "        except Exception as e:\n",
    "          print(\"Failed to complete training: {}\".format(e))\n",
    "          logging.error(\"Failed to complete training: {}\".format(e))\n",
    "          continue\n",
    "        \n",
    "        if isinstance(param_comb, tuple):\n",
    "          param_comb = convert_lists_in_tuple(param_comb)\n",
    "        result = trainer.extract_results()\n",
    "        print(param_comb)\n",
    "        \n",
    "        if optimization_type == 'training_convergence':\n",
    "          param_comb = (param_comb[0], True if param_comb[1] else False)\n",
    "          \n",
    "        results[param_comb] = result\n",
    "        \n",
    "        if optimization_type == 'training_convergence':\n",
    "            training_loss = trainer.losses\n",
    "            results[param_comb]['training_loss'] = training_loss\n",
    "        \n",
    "        print(results[param_comb]['mse_train'])\n",
    "        print(results[param_comb]['mse_test'])\n",
    "        print(results[param_comb]['time_elapsed'])\n",
    "        \n",
    "      if AVERAGED:\n",
    "        mse_train = []\n",
    "        mse_test = []\n",
    "        time_elapsed = []\n",
    "        for _ in range(5):\n",
    "          try:\n",
    "            trainer.train(params_model)\n",
    "          except Exception as e:\n",
    "            print(\"Failed to complete training: {}\".format(e))\n",
    "            logging.error(\"Failed to complete training: {}\".format(e))\n",
    "            continue\n",
    "            \n",
    "          result = trainer.extract_results()\n",
    "          mse_train.append(result['mse_train'])\n",
    "          mse_test.append(result['mse_test'])\n",
    "          time_elapsed.append(result['time_elapsed'])\n",
    "          \n",
    "        results[param_comb] = {\n",
    "            'mse_train': np.mean(mse_train),\n",
    "            'mse_test': np.mean(mse_test),\n",
    "            'time_elapsed': np.mean(time_elapsed)\n",
    "        }\n",
    "        \n",
    "        print(results[param_comb]['mse_train'])\n",
    "        print(results[param_comb]['mse_test'])\n",
    "      \n",
    "      print(\"Iteration:\", i, \"/\", total_iter)\n",
    "      i+=1\n",
    "  \n",
    "  if optimization_type == 'default':\n",
    "    return results, trainer   \n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0\n",
      "0.6119091515864667\n",
      "0.6027185579959544\n",
      "[1.7392802238464355, 1.625025749206543]\n",
      "Iteration: 1 / 1\n"
     ]
    }
   ],
   "source": [
    "results = run('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: {'time_elapsed': [1.7579381465911865, 1.6522245407104492],\n",
       "   'mse_train': Array(0.61190915, dtype=float64),\n",
       "   'mse_test': Array(0.60271856, dtype=float64)}},\n",
       " <run_train_toy.TrainerToy at 0xb1fee6a30>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results/jax_single_network_size.pkl\n"
     ]
    }
   ],
   "source": [
    "reload = True\n",
    "if reload:\n",
    "    formatted_time = time.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    filename = f'results/jax_single_network_size.pkl'\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(results, file)\n",
    "        \n",
    "    print(f\"Results saved to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_result = trainer.extract_results_diffrax(detailed = True)\n",
    "y_pred = detailed_result['odeint_pred']\n",
    "y_pred_test = detailed_result['odeint_pred_test']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(trainer.t, trainer.y[:,0], color = 'blue', label='True Data (Train)', alpha = 0.6)\n",
    "plt.plot(trainer.t, trainer.y[:,1], color = 'blue', alpha = 0.6)\n",
    "plt.scatter(trainer.t, y_pred[:,0], color = 'blue', label='Predicted Trajectory (Train)', alpha = 0.6)\n",
    "plt.scatter(trainer.t, y_pred[:,1], color = 'blue', alpha = 0.6)\n",
    "\n",
    "plt.plot(trainer.t_test, trainer.y_test[:,0], color='#FF8C10', label='True Data (Test)', alpha = 0.6)\n",
    "plt.plot(trainer.t_test, trainer.y_test[:,1], color='#FF8C10', alpha = 0.6)\n",
    "plt.scatter(trainer.t_test, y_pred_test[:,0], color='#FF8C00', label='Predicted Trajectory (Test)', alpha = 0.6)\n",
    "plt.scatter(trainer.t_test, y_pred_test[:,1], color='#FF8C00', alpha = 0.6)\n",
    "\n",
    "plt.title(f\"Sequential-based (Diffrax-JAX) neural ODE training (Van der Pol oscillator)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"State\")\n",
    "plt.legend(loc =\"upper left\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collocation_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
